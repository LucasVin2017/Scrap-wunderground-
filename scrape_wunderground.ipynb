{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016/1/1\n",
      "2016/1/2\n",
      "2016/1/3\n",
      "2016/1/4\n",
      "2016/1/5\n",
      "2016/1/6\n",
      "2016/1/7\n",
      "2016/1/8\n",
      "2016/1/9\n",
      "2016/1/10\n",
      "2016/1/11\n",
      "2016/1/12\n",
      "2016/1/13\n",
      "2016/1/14\n",
      "2016/1/15\n",
      "2016/1/16\n",
      "2016/1/17\n",
      "2016/1/18\n",
      "2016/1/19\n",
      "2016/1/20\n",
      "2016/1/21\n",
      "2016/1/22\n",
      "2016/1/23\n",
      "2016/1/24\n",
      "2016/1/25\n",
      "2016/1/26\n",
      "2016/1/27\n",
      "2016/1/28\n",
      "2016/1/29\n",
      "2016/1/30\n",
      "2016/1/31\n",
      "2016/2/1\n",
      "2016/2/2\n",
      "2016/2/3\n",
      "2016/2/4\n",
      "2016/2/5\n",
      "2016/2/6\n",
      "2016/2/7\n",
      "2016/2/8\n",
      "2016/2/9\n",
      "2016/2/10\n",
      "2016/2/11\n",
      "2016/2/12\n",
      "2016/2/13\n",
      "2016/2/14\n",
      "2016/2/15\n",
      "2016/2/16\n",
      "2016/2/17\n",
      "2016/2/18\n",
      "2016/2/19\n",
      "2016/2/20\n",
      "2016/2/21\n",
      "2016/2/22\n",
      "2016/2/23\n",
      "2016/2/24\n",
      "2016/2/25\n",
      "2016/2/26\n",
      "2016/2/27\n",
      "2016/2/28\n",
      "2016/2/29\n",
      "2016/3/1\n",
      "2016/3/2\n",
      "2016/3/3\n",
      "2016/3/4\n",
      "2016/3/5\n",
      "2016/3/6\n",
      "2016/3/7\n",
      "2016/3/8\n",
      "2016/3/9\n",
      "2016/3/10\n",
      "2016/3/11\n",
      "2016/3/12\n",
      "2016/3/13\n",
      "2016/3/14\n",
      "2016/3/15\n",
      "2016/3/16\n",
      "2016/3/17\n",
      "2016/3/18\n",
      "2016/3/19\n",
      "2016/3/20\n",
      "2016/3/21\n",
      "2016/3/22\n",
      "2016/3/23\n",
      "2016/3/24\n",
      "2016/3/25\n",
      "2016/3/26\n",
      "2016/3/27\n",
      "2016/3/28\n",
      "2016/3/29\n",
      "2016/3/30\n",
      "2016/3/31\n",
      "2016/4/1\n",
      "2016/4/2\n",
      "2016/4/3\n",
      "2016/4/4\n",
      "2016/4/5\n",
      "2016/4/6\n",
      "2016/4/7\n",
      "2016/4/8\n",
      "2016/4/9\n",
      "2016/4/10\n",
      "2016/4/11\n",
      "2016/4/12\n",
      "2016/4/13\n",
      "2016/4/14\n",
      "2016/4/15\n",
      "2016/4/16\n",
      "2016/4/17\n",
      "2016/4/18\n",
      "2016/4/19\n",
      "2016/4/20\n",
      "2016/4/21\n",
      "2016/4/22\n",
      "2016/4/23\n",
      "2016/4/24\n",
      "2016/4/25\n",
      "2016/4/26\n",
      "2016/4/27\n",
      "2016/4/28\n",
      "2016/4/29\n",
      "2016/4/30\n",
      "2016/5/1\n",
      "2016/5/2\n",
      "2016/5/3\n",
      "2016/5/4\n",
      "2016/5/5\n",
      "2016/5/6\n",
      "2016/5/7\n",
      "2016/5/8\n",
      "2016/5/9\n",
      "2016/5/10\n",
      "2016/5/11\n",
      "2016/5/12\n",
      "2016/5/13\n",
      "2016/5/14\n",
      "2016/5/15\n",
      "2016/5/16\n",
      "2016/5/17\n",
      "2016/5/18\n",
      "2016/5/19\n",
      "2016/5/20\n",
      "2016/5/21\n",
      "2016/5/22\n",
      "2016/5/23\n",
      "2016/5/24\n",
      "2016/5/25\n",
      "2016/5/26\n",
      "2016/5/27\n",
      "2016/5/28\n",
      "2016/5/29\n",
      "2016/5/30\n",
      "2016/5/31\n",
      "2016/6/1\n",
      "2016/6/2\n",
      "2016/6/3\n",
      "2016/6/4\n",
      "2016/6/5\n",
      "2016/6/6\n",
      "2016/6/7\n",
      "2016/6/8\n",
      "2016/6/9\n",
      "2016/6/10\n",
      "2016/6/11\n",
      "2016/6/12\n",
      "2016/6/13\n",
      "2016/6/14\n",
      "2016/6/15\n",
      "2016/6/16\n",
      "2016/6/17\n",
      "2016/6/18\n",
      "2016/6/19\n",
      "2016/6/20\n",
      "2016/6/21\n",
      "2016/6/22\n",
      "2016/6/23\n",
      "2016/6/24\n",
      "2016/6/25\n",
      "2016/6/26\n",
      "2016/6/27\n",
      "2016/6/28\n",
      "2016/6/29\n",
      "2016/6/30\n",
      "2016/7/1\n",
      "2016/7/2\n",
      "2016/7/3\n",
      "2016/7/4\n",
      "2016/7/5\n",
      "2016/7/6\n",
      "2016/7/7\n",
      "2016/7/8\n",
      "2016/7/9\n",
      "2016/7/10\n",
      "2016/7/11\n",
      "2016/7/12\n",
      "2016/7/13\n",
      "2016/7/14\n",
      "2016/7/15\n",
      "2016/7/16\n",
      "2016/7/17\n",
      "2016/7/18\n",
      "2016/7/19\n",
      "2016/7/20\n",
      "2016/7/21\n",
      "2016/7/22\n",
      "2016/7/23\n",
      "2016/7/24\n",
      "2016/7/25\n",
      "2016/7/26\n",
      "2016/7/27\n",
      "2016/7/28\n",
      "2016/7/29\n",
      "2016/7/30\n",
      "2016/7/31\n",
      "2016/8/1\n",
      "2016/8/2\n",
      "2016/8/3\n",
      "2016/8/4\n",
      "2016/8/5\n",
      "2016/8/6\n",
      "2016/8/7\n",
      "2016/8/8\n",
      "2016/8/9\n",
      "2016/8/10\n",
      "2016/8/11\n",
      "2016/8/12\n",
      "2016/8/13\n",
      "2016/8/14\n",
      "2016/8/15\n",
      "2016/8/16\n",
      "2016/8/17\n",
      "2016/8/18\n",
      "2016/8/19\n",
      "2016/8/20\n",
      "2016/8/21\n",
      "2016/8/22\n",
      "2016/8/23\n",
      "2016/8/24\n",
      "2016/8/25\n",
      "2016/8/26\n",
      "2016/8/27\n",
      "2016/8/28\n",
      "2016/8/29\n",
      "2016/8/30\n",
      "2016/8/31\n",
      "2016/9/1\n",
      "2016/9/2\n",
      "2016/9/3\n",
      "2016/9/4\n",
      "2016/9/5\n",
      "2016/9/6\n",
      "2016/9/7\n",
      "2016/9/8\n",
      "2016/9/9\n",
      "2016/9/10\n",
      "2016/9/11\n",
      "2016/9/12\n",
      "2016/9/13\n",
      "2016/9/14\n",
      "2016/9/15\n",
      "2016/9/16\n",
      "2016/9/17\n",
      "2016/9/18\n",
      "2016/9/19\n",
      "2016/9/20\n",
      "2016/9/21\n",
      "2016/9/22\n",
      "2016/9/23\n",
      "2016/9/24\n",
      "2016/9/25\n",
      "2016/9/26\n",
      "2016/9/27\n",
      "2016/9/28\n",
      "2016/9/29\n",
      "2016/9/30\n",
      "2016/10/1\n",
      "2016/10/2\n",
      "2016/10/3\n"
     ]
    }
   ],
   "source": [
    "#importação de bibliotecas\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import csv\n",
    "import time\n",
    "#abertura do arquivo para gravação\n",
    "with open ('wunderground__2016.csv','w') as arquivo:\n",
    "    writer = csv.writer (arquivo)\n",
    "    #inserção do nomas das colunas no arquivo\n",
    "    writer.writerow((\"Data\",'Temp_media','Temp_max_atual','Temp_max_media','Temp_min_atual','Temp_min_media','Ponto_orvalho','Precipitacao','Precipitacao_Media','Nivel_do_mar','Velocidade_do_vento','Maxima_do_vent','Null'))\n",
    "#função que faz a coleta dos dados\n",
    "def scrape_estado(estado):\n",
    "\n",
    "    #laço de repetição que verifica as datas extrai os dados e os insere no arquivo\n",
    "    for vYear in range(2016, 2017):\n",
    "        for vMonth in range(1, 13):\n",
    "            for vDay in range(1, 32):\n",
    "                \n",
    "                if vYear % 4 == 0:\n",
    "                    if vMonth == 2 and vDay > 29:\n",
    "                        break\n",
    "                else:\n",
    "                    if vMonth == 2 and vDay > 28:\n",
    "                        break\n",
    "                \n",
    "                if vMonth in [4, 6, 9, 11] and vDay > 30:\n",
    "                    break\n",
    "                \n",
    "                #variável de date recebe os valores das datas\n",
    "                theDate = str(vYear) + \"/\" + str(vMonth) + \"/\" + str(vDay)\n",
    "                #date_enconded formata a data para inserção no arquivo \n",
    "                date_enconded= theDate+','\n",
    "                print (theDate)\n",
    "                                \n",
    "                URL = 'http://www.wunderground.com/history/airport/'+estado+'/'+theDate+'/DailyHistory.html'\n",
    "                print (URL)\n",
    "                #requisição da páginas HTML\n",
    "                html = urlopen(URL).read().decode('utf-8')\n",
    "                #formtação da páginas com método Beautifulsoup  \n",
    "                soup = BeautifulSoup (html, \"html.parser\")\n",
    "                #extração da tabela historyTable tag span e classe wx-value\n",
    "                dados_clima = soup.find(id='historyTable').find_all('span', class_='wx-value')\n",
    "                #extração da tabela historyTable e tag td\n",
    "                dados_clima_ = soup.find(id='historyTable').find_all('td')\n",
    "                #extrção das informações\n",
    "                try:\n",
    "                    Temp_media = dados_clima[0].text+','\n",
    "                #tratamento de erros.\n",
    "                except IndentationError:\n",
    "                    Temp_media='N/A'+','\n",
    "                try:\n",
    "                    Temp_max_atual = dados_clima[1].text+','\n",
    "                except IndexError:\n",
    "                    Temp_max_atual='N/A'+','\n",
    "                try:\n",
    "                    Temp_max_media = dados_clima[2].text+','\n",
    "                except IndexError:\n",
    "                    Temp_max_media = 'N/A'+','\n",
    "                try:\n",
    "                    Temp_min_atual = dados_clima[3].text+','\n",
    "                except IndexError:\n",
    "                    Temp_min_atual+','\n",
    "                try:\n",
    "                    Temp_min_media = dados_clima[4].text+','\n",
    "                except IndexError:\n",
    "                    Temp_min_media='N/A'+','\n",
    "                try:\n",
    "                    Ponto_orvalho = dados_clima[5].text+','\n",
    "                except IndexError:\n",
    "                    Ponto_orvalho='N/A'+','\n",
    "                try:\n",
    "                    Precipitacao = dados_clima[6].text+','\n",
    "                except IndexError:\n",
    "                    Precipitacao='N/A'+','\n",
    "                try:\n",
    "                    Precipitacao_Media = dados_clima[7].text+','\n",
    "                except IndexError:\n",
    "                    Precipitacao_Media='N/A'+','\n",
    "                try:\n",
    "                    Nivel_do_mar = dados_clima[8].text+','\n",
    "                except IndexError:\n",
    "                    Nivel_do_mar='N/A'+','\n",
    "                try:\n",
    "                    Velocidade_do_vento = dados_clima[9].text+','\n",
    "                except IndexError:\n",
    "                    Velocidade_do_vento = 'N/A'+','\n",
    "                try:\n",
    "                    Maxima_do_vent = dados_clima[10].text+','\n",
    "                except IndexError:\n",
    "                    Maxima_do_vent = 'N/A'+','\n",
    "                #abertura do arquivo para adição \n",
    "                with open ('wunderground__2016.csv','a',newline='') as arquivo:\n",
    "                    writer = csv.writer (arquivo, delimiter=' ',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                    #gravação dos dados no arquivo\n",
    "                    writer.writerow(((date_enconded,Temp_media,Temp_max_atual,Temp_max_media,Temp_min_atual,Temp_min_media,\n",
    "                                Ponto_orvalho,Precipitacao,Precipitacao_Media,Nivel_do_mar,Velocidade_do_vento,Maxima_do_vent)))\n",
    "               \n",
    "               \n",
    "            \n",
    "for estado in ['SBMK']:\n",
    "    scrape_estado(estado)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
